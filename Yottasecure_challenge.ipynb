{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2defd361",
   "metadata": {},
   "source": [
    "# Minimal RAG / Vector Search and Security Data Integration\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1) A minimal Retrieval-Augmented Generation (RAG) pipeline using a from-scratch TF-IDF index and cosine similarity over a small payments corpus.\n",
    "\n",
    "2) A security data integration workflow:\n",
    "   - Load and analyze synthetic authentication logs.\n",
    "   - Detect suspicious behavior.\n",
    "   - Use the same vector search index to retrieve relevant runbook steps.\n",
    "   - Compose a response using retrieved context (RAG-style).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03345d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready.\n"
     ]
    }
   ],
   "source": [
    "# Minimal, dependency-light setup\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    TOKEN_RE = re.compile(r\"[A-Za-z0-9_]+\")\n",
    "    return [t.lower() for t in TOKEN_RE.findall(text or \"\")]\n",
    "\n",
    "def sentence_split(text: str) -> List[str]:\n",
    "    parts = re.split(r'(?<=[.!?])\\s+', (text or \"\").strip())\n",
    "    return [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "print(\"Environment ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79928a18",
   "metadata": {},
   "source": [
    "## Part A: Payments Knowledge Base\n",
    "\n",
    "We synthesize a small corpus about payments platforms, chunk it by sentence, and build a TF-IDF vector index from scratch for retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3097c24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,\n",
       " [{'doc_id': 'doc1',\n",
       "   'title': 'Payments Gateway Basics',\n",
       "   'chunk_id': 'doc1_c1',\n",
       "   'text': 'A payments gateway authorizes, captures, and settles transactions.'},\n",
       "  {'doc_id': 'doc1',\n",
       "   'title': 'Payments Gateway Basics',\n",
       "   'chunk_id': 'doc1_c2',\n",
       "   'text': 'It communicates with acquiring banks, card networks, and issuing banks.'},\n",
       "  {'doc_id': 'doc1',\n",
       "   'title': 'Payments Gateway Basics',\n",
       "   'chunk_id': 'doc1_c3',\n",
       "   'text': 'Key flows include authorization, capture, refund, and void.'}])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [\n",
    "    {\n",
    "        \"id\": \"doc1\",\n",
    "        \"title\": \"Payments Gateway Basics\",\n",
    "        \"text\": (\n",
    "            \"A payments gateway authorizes, captures, and settles transactions. \"\n",
    "            \"It communicates with acquiring banks, card networks, and issuing banks. \"\n",
    "            \"Key flows include authorization, capture, refund, and void. \"\n",
    "            \"PCI compliance and tokenization ensure that sensitive card data is never directly stored.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc2\",\n",
    "        \"title\": \"Fraud and Risk\",\n",
    "        \"text\": (\n",
    "            \"Fraud detection in payments involves device fingerprinting, velocity checks, and risk scoring. \"\n",
    "            \"Rules can block transactions based on geolocation, BIN ranges, or mismatched AVS and CVV. \"\n",
    "            \"Machine learning models can be layered on top of rules to reduce false positives.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc3\",\n",
    "        \"title\": \"Ledger and Reconciliation\",\n",
    "        \"text\": (\n",
    "            \"A double-entry ledger records debits and credits for all money movements. \"\n",
    "            \"Reconciliation aligns processor reports with internal records to detect discrepancies. \"\n",
    "            \"Payouts aggregate settled funds and transfer balances to merchant bank accounts on a schedule.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc4\",\n",
    "        \"title\": \"Checkout UX and Tokenization\",\n",
    "        \"text\": (\n",
    "            \"Hosted fields and iframes isolate card inputs to reduce PCI scope. \"\n",
    "            \"Tokenization replaces primary account numbers with opaque tokens. \"\n",
    "            \"A smooth checkout can improve conversion, support digital wallets, and provide client-side validation.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc5\",\n",
    "        \"title\": \"Fees and FX\",\n",
    "        \"text\": (\n",
    "            \"Payment processing revenue commonly uses a percent plus fixed fee per transaction. \"\n",
    "            \"Cross-border payments may involve foreign exchange spreads and scheme fees. \"\n",
    "            \"Providers can also monetize value-added services like chargeback protection and analytics.\"\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "chunks = []\n",
    "for d in docs:\n",
    "    for i, sent in enumerate(sentence_split(d[\"text\"])):\n",
    "        chunks.append({\n",
    "            \"doc_id\": d[\"id\"],\n",
    "            \"title\": d[\"title\"],\n",
    "            \"chunk_id\": f\"{d['id']}_c{i+1}\",\n",
    "            \"text\": sent\n",
    "        })\n",
    "\n",
    "len(chunks), chunks[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e7d4fb",
   "metadata": {},
   "source": [
    "### Build a from-scratch TF-IDF index\n",
    "\n",
    "We compute:\n",
    "- Vocabulary over all chunk texts\n",
    "- Term frequencies per chunk\n",
    "- Document frequencies and IDF\n",
    "- TF-IDF matrix with L2 normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdeda406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 147\n",
      "Chunks indexed:  16\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary\n",
    "vocab: Dict[str, int] = {}\n",
    "doc_tokens: List[List[str]] = []\n",
    "for ch in chunks:\n",
    "    toks = tokenize(ch[\"text\"])\n",
    "    doc_tokens.append(toks)\n",
    "    for t in toks:\n",
    "        if t not in vocab:\n",
    "            vocab[t] = len(vocab)\n",
    "\n",
    "V = len(vocab)\n",
    "D = len(chunks)\n",
    "\n",
    "# Term frequency matrix\n",
    "tf = np.zeros((D, V), dtype=float)\n",
    "for i, toks in enumerate(doc_tokens):\n",
    "    for t in toks:\n",
    "        tf[i, vocab[t]] += 1.0\n",
    "\n",
    "# Document frequency and IDF (smoothed)\n",
    "df = np.count_nonzero(tf > 0, axis=0)\n",
    "idf = np.log((1 + D) / (1 + df)) + 1.0\n",
    "\n",
    "# TF-IDF with L2 normalization\n",
    "tfidf = tf * idf\n",
    "norms = np.linalg.norm(tfidf, axis=1, keepdims=True)\n",
    "norms[norms == 0] = 1.0\n",
    "tfidf = tfidf / norms\n",
    "\n",
    "print(f\"Vocabulary size: {V}\")\n",
    "print(f\"Chunks indexed:  {D}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b204b7f4",
   "metadata": {},
   "source": [
    "### Query, retrieve top-k chunks, and compose a simple RAG-style answer\n",
    "\n",
    "We compute a query TF-IDF vector in the same space, cosine similarities, and return the top-k chunks.  \n",
    "We then produce a naive answer by concatenating the most relevant chunk texts as context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "956fb8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How does tokenization help PCI scope and what are common gateway flows?\n",
      "\n",
      "Relevant context:\n",
      "- Hosted fields and iframes isolate card inputs to reduce PCI scope.\n",
      "- PCI compliance and tokenization ensure that sensitive card data is never directly stored.\n",
      "- A payments gateway authorizes, captures, and settles transactions.\n",
      "- Key flows include authorization, capture, refund, and void.\n",
      "\n",
      "Naive answer:\n",
      "Based on the retrieved context, the system supports key payment flows such as authorization, capture, refund, and void, with PCI scope reduction via hosted fields and tokenization. Fraud controls involve rules and optional machine learning. A double-entry ledger and reconciliation align money movements with processor reports, while fees typically combine a percent plus fixed component; cross-border FX introduces additional spreads.\n"
     ]
    }
   ],
   "source": [
    "def vectorize_query(query: str) -> np.ndarray:\n",
    "    q_tf = np.zeros((V,), dtype=float)\n",
    "    for tok in tokenize(query):\n",
    "        if tok in vocab:\n",
    "            q_tf[vocab[tok]] += 1.0\n",
    "    q_vec = q_tf * idf\n",
    "    n = np.linalg.norm(q_vec)\n",
    "    return q_vec / (n if n else 1.0)\n",
    "\n",
    "def retrieve(query: str, k: int = 4) -> List[Tuple[float, Dict]]:\n",
    "    q = vectorize_query(query)\n",
    "    sims = tfidf @ q\n",
    "    idx = np.argsort(-sims)[:k]\n",
    "    return [(float(sims[i]), chunks[i]) for i in idx]\n",
    "\n",
    "def rag_answer(query: str, k: int = 4) -> Dict:\n",
    "    hits = retrieve(query, k=k)\n",
    "    context = \"\\n\".join([f\"- {c['text']}\" for _, c in hits])\n",
    "    answer = (\n",
    "        f\"Query: {query}\\n\\n\"\n",
    "        f\"Relevant context:\\n{context}\\n\\n\"\n",
    "        f\"Naive answer:\\n\"\n",
    "        f\"Based on the retrieved context, the system supports key payment flows such as authorization, capture, refund, and void, \"\n",
    "        f\"with PCI scope reduction via hosted fields and tokenization. Fraud controls involve rules and optional machine learning. \"\n",
    "        f\"A double-entry ledger and reconciliation align money movements with processor reports, while fees typically combine a \"\n",
    "        f\"percent plus fixed component; cross-border FX introduces additional spreads.\"\n",
    "    )\n",
    "    return {\"hits\": hits, \"answer\": answer}\n",
    "\n",
    "# Demo\n",
    "demo = rag_answer(\"How does tokenization help PCI scope and what are common gateway flows?\")\n",
    "print(demo[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d39e44f",
   "metadata": {},
   "source": [
    "## Part B: Security Data Integration\n",
    "\n",
    "We create a synthetic authentication log dataset, detect suspicious activity, and then use the vector index over a small set of security runbooks to assemble response guidance with a RAG-style approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde48a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user</th>\n",
       "      <th>ip</th>\n",
       "      <th>event</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-21 09:00:00</td>\n",
       "      <td>dave</td>\n",
       "      <td>203.0.113.169</td>\n",
       "      <td>auth_attempt</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-21 09:05:00</td>\n",
       "      <td>dave</td>\n",
       "      <td>203.0.113.167</td>\n",
       "      <td>auth_attempt</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-21 09:06:00</td>\n",
       "      <td>alice</td>\n",
       "      <td>203.0.113.196</td>\n",
       "      <td>auth_attempt</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-21 09:07:00</td>\n",
       "      <td>bob</td>\n",
       "      <td>203.0.113.179</td>\n",
       "      <td>auth_attempt</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-21 09:07:00</td>\n",
       "      <td>bob</td>\n",
       "      <td>203.0.113.58</td>\n",
       "      <td>auth_attempt</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-10-21 09:08:00</td>\n",
       "      <td>carol</td>\n",
       "      <td>203.0.113.25</td>\n",
       "      <td>auth_attempt</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-10-21 09:09:00</td>\n",
       "      <td>dave</td>\n",
       "      <td>203.0.113.178</td>\n",
       "      <td>auth_attempt</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-10-21 09:12:00</td>\n",
       "      <td>dave</td>\n",
       "      <td>203.0.113.148</td>\n",
       "      <td>auth_attempt</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-10-21 09:15:00</td>\n",
       "      <td>carol</td>\n",
       "      <td>203.0.113.201</td>\n",
       "      <td>auth_attempt</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-10-21 09:16:00</td>\n",
       "      <td>dave</td>\n",
       "      <td>203.0.113.142</td>\n",
       "      <td>auth_attempt</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp   user             ip         event   status\n",
       "0 2025-10-21 09:00:00   dave  203.0.113.169  auth_attempt  success\n",
       "1 2025-10-21 09:05:00   dave  203.0.113.167  auth_attempt  success\n",
       "2 2025-10-21 09:06:00  alice  203.0.113.196  auth_attempt  success\n",
       "3 2025-10-21 09:07:00    bob  203.0.113.179  auth_attempt  success\n",
       "4 2025-10-21 09:07:00    bob   203.0.113.58  auth_attempt  success\n",
       "5 2025-10-21 09:08:00  carol   203.0.113.25  auth_attempt  failure\n",
       "6 2025-10-21 09:09:00   dave  203.0.113.178  auth_attempt  success\n",
       "7 2025-10-21 09:12:00   dave  203.0.113.148  auth_attempt  success\n",
       "8 2025-10-21 09:15:00  carol  203.0.113.201  auth_attempt  success\n",
       "9 2025-10-21 09:16:00   dave  203.0.113.142  auth_attempt  success"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "users = [\"alice\", \"bob\", \"carol\", \"dave\"]\n",
    "base_time = datetime(2025, 10, 21, 9, 0, 0)\n",
    "\n",
    "def random_ip():\n",
    "    return f\"203.0.113.{rng.integers(1, 255)}\"\n",
    "\n",
    "rows = []\n",
    "# Normal activity\n",
    "for hr in range(0, 4):  # 4 hours\n",
    "    t = base_time + timedelta(hours=hr)\n",
    "    for _ in range(50):\n",
    "        rows.append({\n",
    "            \"timestamp\": t + timedelta(minutes=int(rng.integers(0, 60))),\n",
    "            \"user\": rng.choice(users),\n",
    "            \"ip\": random_ip(),\n",
    "            \"event\": \"auth_attempt\",\n",
    "            \"status\": \"success\" if rng.random() > 0.15 else \"failure\"\n",
    "        })\n",
    "\n",
    "# Suspicious burst from a single IP\n",
    "bad_ip = \"198.51.100.77\"\n",
    "for m in range(30):\n",
    "    rows.append({\n",
    "        \"timestamp\": base_time + timedelta(hours=2, minutes=m),\n",
    "        \"user\": rng.choice(users),\n",
    "        \"ip\": bad_ip,\n",
    "        \"event\": \"auth_attempt\",\n",
    "        \"status\": \"failure\"\n",
    "    })\n",
    "\n",
    "logs = pd.DataFrame(rows).sort_values(\"timestamp\").reset_index(drop=True)\n",
    "logs.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0497f6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top failure IPs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>failures</th>\n",
       "      <th>zscore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198.51.100.77</th>\n",
       "      <td>30</td>\n",
       "      <td>6.002193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203.0.113.105</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.162221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203.0.113.106</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.162221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203.0.113.112</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.162221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203.0.113.134</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.162221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203.0.113.141</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.162221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203.0.113.150</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.162221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203.0.113.155</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.162221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203.0.113.162</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.162221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203.0.113.174</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.162221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               failures    zscore\n",
       "ip                               \n",
       "198.51.100.77        30  6.002193\n",
       "203.0.113.105         1 -0.162221\n",
       "203.0.113.106         1 -0.162221\n",
       "203.0.113.112         1 -0.162221\n",
       "203.0.113.134         1 -0.162221\n",
       "203.0.113.141         1 -0.162221\n",
       "203.0.113.150         1 -0.162221\n",
       "203.0.113.155         1 -0.162221\n",
       "203.0.113.162         1 -0.162221\n",
       "203.0.113.174         1 -0.162221"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Suspect IPs (zscore >= 2):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>failures</th>\n",
       "      <th>zscore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198.51.100.77</th>\n",
       "      <td>30</td>\n",
       "      <td>6.002193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               failures    zscore\n",
       "ip                               \n",
       "198.51.100.77        30  6.002193"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failures by user:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "user\n",
       "alice    18\n",
       "carol    18\n",
       "dave     17\n",
       "bob      14\n",
       "Name: failures, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aggregate failures by IP and user\n",
    "failures = logs[logs[\"status\"] == \"failure\"]\n",
    "by_ip = failures.groupby(\"ip\").size().sort_values(ascending=False).rename(\"failures\")\n",
    "by_user = failures.groupby(\"user\").size().sort_values(ascending=False).rename(\"failures\")\n",
    "\n",
    "# Simple anomaly via z-score on failures per IP\n",
    "ip_counts = by_ip.to_frame()\n",
    "mu = ip_counts[\"failures\"].mean()\n",
    "sigma = ip_counts[\"failures\"].std(ddof=1) if len(ip_counts) > 1 else 0.0\n",
    "ip_counts[\"zscore\"] = 0.0 if sigma == 0 else (ip_counts[\"failures\"] - mu) / sigma\n",
    "\n",
    "suspect_ips = ip_counts[ip_counts[\"zscore\"] >= 2.0].sort_values(\"zscore\", ascending=False)\n",
    "\n",
    "print(\"Top failure IPs:\")\n",
    "display(ip_counts.sort_values(\"failures\", ascending=False).head(10))\n",
    "\n",
    "print(\"\\nSuspect IPs (zscore >= 2):\")\n",
    "display(suspect_ips)\n",
    "\n",
    "print(\"\\nFailures by user:\")\n",
    "display(by_user)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f420154",
   "metadata": {},
   "source": [
    "### Security runbooks corpus\n",
    "\n",
    "We define a small corpus of security runbooks and guidance, then reuse the same TF-IDF machinery to retrieve relevant steps for the detected incident.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8296a65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Security vocab size: 84\n",
      "Security chunks:     9\n"
     ]
    }
   ],
   "source": [
    "security_docs = [\n",
    "    {\n",
    "        \"id\": \"sec1\",\n",
    "        \"title\": \"Credential Stuffing Runbook\",\n",
    "        \"text\": (\n",
    "            \"Detect bursts of authentication failures from a single IP, especially across multiple accounts. \"\n",
    "            \"Mitigations include enabling rate limiting, enforcing CAPTCHA, blocking abusive IPs, and requiring MFA enrollment. \"\n",
    "            \"Review access logs and notify impacted users to reset passwords if necessary.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"sec2\",\n",
    "        \"title\": \"Brute Force Login Runbook\",\n",
    "        \"text\": (\n",
    "            \"Repeated login failures for one or more accounts could indicate brute force attempts. \"\n",
    "            \"Apply progressive account lockouts, IP reputation checks, and throttle authentication endpoints. \"\n",
    "            \"Correlate unusual login times and geolocations.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"sec3\",\n",
    "        \"title\": \"Account Takeover Triage\",\n",
    "        \"text\": (\n",
    "            \"If an account shows anomalous access patterns, reset session tokens and require MFA. \"\n",
    "            \"Validate user identity, examine device fingerprints, and check for password reuse. \"\n",
    "            \"Search for indicators of compromise related to the source IP or ASN.\"\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "security_chunks = []\n",
    "for d in security_docs:\n",
    "    for i, sent in enumerate(sentence_split(d[\"text\"])):\n",
    "        security_chunks.append({\n",
    "            \"doc_id\": d[\"id\"],\n",
    "            \"title\": d[\"title\"],\n",
    "            \"chunk_id\": f\"{d['id']}_c{i+1}\",\n",
    "            \"text\": sent\n",
    "        })\n",
    "\n",
    "# Build a separate TF-IDF index for security runbooks (kept independent for clarity)\n",
    "sec_vocab: Dict[str, int] = {}\n",
    "sec_tokens: List[List[str]] = []\n",
    "for ch in security_chunks:\n",
    "    toks = tokenize(ch[\"text\"])\n",
    "    sec_tokens.append(toks)\n",
    "    for t in toks:\n",
    "        if t not in sec_vocab:\n",
    "            sec_vocab[t] = len(sec_vocab)\n",
    "\n",
    "SV = len(sec_vocab)\n",
    "SD = len(security_chunks)\n",
    "\n",
    "sec_tf = np.zeros((SD, SV), dtype=float)\n",
    "for i, toks in enumerate(sec_tokens):\n",
    "    for t in toks:\n",
    "        sec_tf[i, sec_vocab[t]] += 1.0\n",
    "\n",
    "sec_df = np.count_nonzero(sec_tf > 0, axis=0)\n",
    "sec_idf = np.log((1 + SD) / (1 + sec_df)) + 1.0\n",
    "\n",
    "sec_tfidf = sec_tf * sec_idf\n",
    "sec_norms = np.linalg.norm(sec_tfidf, axis=1, keepdims=True)\n",
    "sec_norms[sec_norms == 0] = 1.0\n",
    "sec_tfidf = sec_tfidf / sec_norms\n",
    "\n",
    "print(f\"Security vocab size: {SV}\")\n",
    "print(f\"Security chunks:     {SD}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb5a9f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec_vectorize_query(query: str) -> np.ndarray:\n",
    "    q_tf = np.zeros((SV,), dtype=float)\n",
    "    for tok in tokenize(query):\n",
    "        if tok in sec_vocab:\n",
    "            q_tf[sec_vocab[tok]] += 1.0\n",
    "    q_vec = q_tf * sec_idf\n",
    "    n = np.linalg.norm(q_vec)\n",
    "    return q_vec / (n if n else 1.0)\n",
    "\n",
    "def sec_retrieve(query: str, k: int = 4) -> List[Tuple[float, Dict]]:\n",
    "    q = sec_vectorize_query(query)\n",
    "    sims = sec_tfidf @ q\n",
    "    idx = np.argsort(-sims)[:k]\n",
    "    return [(float(sims[i]), security_chunks[i]) for i in idx]\n",
    "\n",
    "def sec_rag_guidance(incident_summary: str, k: int = 4) -> Dict:\n",
    "    hits = sec_retrieve(incident_summary, k=k)\n",
    "    steps = \"\\n\".join([f\"- {c['text']}\" for _, c in hits])\n",
    "    guidance = (\n",
    "        f\"Incident summary: {incident_summary}\\n\\n\"\n",
    "        f\"Relevant runbook guidance:\\n{steps}\\n\\n\"\n",
    "        f\"Actionable plan:\\n\"\n",
    "        f\"1) Enforce rate limiting and throttle abusive sources.\\n\"\n",
    "        f\"2) Consider temporary IP block or CAPTCHA for the offending IPs.\\n\"\n",
    "        f\"3) Require MFA enrollment for affected users and reset passwords as needed.\\n\"\n",
    "        f\"4) Review access patterns, correlate geolocation and device fingerprints.\\n\"\n",
    "        f\"5) Notify stakeholders and document containment and recovery steps.\"\n",
    "    )\n",
    "    return {\"hits\": hits, \"guidance\": guidance}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af278c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident summary:\n",
      "Detected a burst of failed authentications from IP 198.51.100.77 with 30 failures across users [np.str_('dave'), np.str_('alice'), np.str_('carol'), np.str_('bob')]. Possible credential stuffing or brute force.\n",
      "\n",
      "RAG-style guidance:\n",
      "Incident summary: Detected a burst of failed authentications from IP 198.51.100.77 with 30 failures across users [np.str_('dave'), np.str_('alice'), np.str_('carol'), np.str_('bob')]. Possible credential stuffing or brute force.\n",
      "\n",
      "Relevant runbook guidance:\n",
      "- Detect bursts of authentication failures from a single IP, especially across multiple accounts.\n",
      "- Repeated login failures for one or more accounts could indicate brute force attempts.\n",
      "- Search for indicators of compromise related to the source IP or ASN.\n",
      "- Review access logs and notify impacted users to reset passwords if necessary.\n",
      "\n",
      "Actionable plan:\n",
      "1) Enforce rate limiting and throttle abusive sources.\n",
      "2) Consider temporary IP block or CAPTCHA for the offending IPs.\n",
      "3) Require MFA enrollment for affected users and reset passwords as needed.\n",
      "4) Review access patterns, correlate geolocation and device fingerprints.\n",
      "5) Notify stakeholders and document containment and recovery steps.\n"
     ]
    }
   ],
   "source": [
    "# Build an incident summary automatically from analytics results\n",
    "if not suspect_ips.empty:\n",
    "    top_ip = suspect_ips.index[0]\n",
    "    top_count = int(ip_counts.loc[top_ip, \"failures\"])\n",
    "    affected_users = (\n",
    "        failures[failures[\"ip\"] == top_ip][\"user\"]\n",
    "        .value_counts()\n",
    "        .index.tolist()\n",
    "    )\n",
    "    incident = (\n",
    "        f\"Detected a burst of failed authentications from IP {top_ip} \"\n",
    "        f\"with {top_count} failures across users {affected_users}. \"\n",
    "        f\"Possible credential stuffing or brute force.\"\n",
    "    )\n",
    "else:\n",
    "    incident = \"No suspicious IPs detected; failure rates within normal bands.\"\n",
    "\n",
    "print(\"Incident summary:\")\n",
    "print(incident)\n",
    "\n",
    "# Retrieve runbook guidance with the security runbooks index\n",
    "sec_demo = sec_rag_guidance(incident_summary=incident, k=4)\n",
    "print(\"\\nRAG-style guidance:\")\n",
    "print(sec_demo[\"guidance\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5549c2e1",
   "metadata": {},
   "source": [
    "### Compose a unified report\n",
    "\n",
    "We can synthesize both the payments RAG and the security guidance into a single structured output (for example, a JSON report your system could send to downstream services).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88b8395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"generated_at\": \"2025-10-21T20:38:00.417163Z\",\n",
      "  \"security\": {\n",
      "    \"incident_summary\": \"Detected a burst of failed authentications from IP 198.51.100.77 with 30 failures across users [np.str_('dave'), np.str_('alice'), np.str_('carol'), np.str_('bob')]. Possible credential stuffing or brute force.\",\n",
      "    \"suspect_ips\": [\n",
      "      {\n",
      "        \"ip\": \"198.51.100.77\",\n",
      "        \"failures\": 30,\n",
      "        \"zscore\": 6.002192581838214\n",
      "      }\n",
      "    ],\n",
      "    \"guidance\": \"Incident summary: Detected a burst of failed authentications from IP 198.51.100.77 with 30 failures across users [np.str_('dave'), np.str_('alice'), np.str_('carol'), np.str_('bob')]. Possible credential stuffing or brute force.\\n\\nRelevant runbook guidance:\\n- Detect bursts of authentication failures from a single IP, especially across multiple accounts.\\n- Repeated login failures for one or more accounts could indicate brute force attempts.\\n- Search for indicators of compromise related to the source IP or ASN.\\n- Review access logs and notify impacted users to reset passwords if necessary.\\n\\nActionable plan:\\n1) Enforce rate limiting and throttle abusive sources.\\n2) Consider temporary IP block or CAPTCHA for the offending IPs.\\n3) Require MFA enrollment for affected users and reset passwords as needed.\\n4) Review access patterns, correlate geolocation and device fingerprints.\\n5) Notify stakeholders and document containment and recovery steps.\"\n",
      "  },\n",
      "  \"payments\": {\n",
      "    \"query\": \"What are common gateway flows and how does tokenization reduce PCI scope?\",\n",
      "    \"top_chunks\": [\n",
      "      {\n",
      "        \"chunk_id\": \"doc4_c1\",\n",
      "        \"text\": \"Hosted fields and iframes isolate card inputs to reduce PCI scope.\"\n",
      "      },\n",
      "      {\n",
      "        \"chunk_id\": \"doc1_c4\",\n",
      "        \"text\": \"PCI compliance and tokenization ensure that sensitive card data is never directly stored.\"\n",
      "      },\n",
      "      {\n",
      "        \"chunk_id\": \"doc1_c1\",\n",
      "        \"text\": \"A payments gateway authorizes, captures, and settles transactions.\"\n",
      "      }\n",
      "    ],\n",
      "    \"answer\": \"Query: What are common gateway flows and how does tokenization reduce PCI scope?\\n\\nRelevant context:\\n- Hosted fields and iframes isolate card inputs to reduce PCI scope.\\n- PCI compliance and tokenization ensure that sensitive card data is never directly stored.\\n- A payments gateway authorizes, captures, and settles transactions.\\n\\nNaive answer:\\nBased on the retrieved context, the system supports key payment flows such as authorization, capture, refund, and void, with PCI scope reduction via hosted fields and tokenization. Fraud controls involve rules and optional machine learning. A double-entry ledger and reconciliation align money movements with processor reports, while fees typically combine a percent plus fixed component; cross-border FX introduces additional spreads.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def payments_rag_snippet(query: str) -> Dict:\n",
    "    res = rag_answer(query, k=3)\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"top_chunks\": [{\"chunk_id\": c[\"chunk_id\"], \"text\": c[\"text\"]} for _, c in res[\"hits\"]],\n",
    "        \"answer\": res[\"answer\"],\n",
    "    }\n",
    "\n",
    "report = {\n",
    "    \"generated_at\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"security\": {\n",
    "        \"incident_summary\": incident,\n",
    "        \"suspect_ips\": suspect_ips.reset_index().to_dict(orient=\"records\"),\n",
    "        \"guidance\": sec_demo[\"guidance\"],\n",
    "    },\n",
    "    \"payments\": payments_rag_snippet(\n",
    "        \"What are common gateway flows and how does tokenization reduce PCI scope?\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(json.dumps(report, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42abaa81",
   "metadata": {},
   "source": [
    "## Notes and Next Steps\n",
    "\n",
    "- Replace the synthetic corpora with your real documents or runbooks.\n",
    "- Swap the from-scratch TF-IDF with production embeddings and a vector DB.\n",
    "- Plug in your preferred LLM to synthesize final answers using the retrieved context.\n",
    "- Expand the security pipeline with:\n",
    "  - IP reputation lookups\n",
    "  - Geo and ASN enrichment\n",
    "  - Correlation across systems (IdP, WAF, SIEM)\n",
    "  - Alert routing and case management\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
